<!DOCTYPE html>
<html>
    <head>
        <title>
            TER3M_Emerging_Topics
        </title>
        <link href= "style.css" type= "text/css" rel= "stylesheet" />
    </head>

    <body>
        <h1> Algorithms & Time Complexity </h1>
        <h1> - </h1>
        <h1> The Basis of Computing </h1>
        <p>
          The use of algorithms and time complexity in the field of computer science are two that are not only extremely important, but also go hand in hand with one another. Algorithms allow us to solve seemingly daunting problems in a predefined and linear manner, and time complexity allows us to determine the most effeicent method of solving that particular problem. In this website, we will not only go into the history of where these two concepts began, but will develop a basic idea of what these two concepts are, as well as when and where they come into play within the world of computing.
        </p>
        <div class="space"></div>

        <h2> What is an algorithm? </h2>
        <img src= image_2.png height= "150px" />

            <ul>
                <li>
                  When dealing with computer science and software as a whole, the idea of using and implementing an algorithm can be one that is not only extremely necessary, but simpler than many think. Speaking in lay terms, an algorithm is simply a set of predefined instructions fed to a computer with the purpose of solving a problem, or reaching a certain solution. To use a comparison, an algorithm is to computer science, what a recipe is to baking, in that they both outline a series of steps to be preformed, with the goal of reaching a desired outcome. In the case of a computer, however,  "the word for a recipe is a procedure, and the ingredients are called inputs. Your computer looks at your procedure, follows it to the letter, and you get to see the results, which are called outputs" [1].
                </li>
                <br>
                <li>
                  It is also important to note that an algorithm is not written in any particular programming language. Algorithm design is generally accomplished in something known as pseudocode, which is a semi-programming language that is used to better convey the steps in an algorithm. In addition to this, algorithms can be depicted graphically in what is known as a flowchart. Flowcharts help the user visualize not only the decisions to be made by the computer, but the sequential nature of the algorithm, depicting how each step leads to a different step based on the criteria filled. Moreover, all algorithms have certain characteristics that make them functional and defined as such. All algorithms should have input values from a specified set, which then leads to a cooresponding output. All algorithms must terminate after a finite number of steps, and all of said steps must be precisely defined. 
                </li>
                <div class="space"></div>
            </ul>

        <h2> What is the time complexity of an algorithm? </h2>
        <img src= Image_8.png height= "280px" />
        <ul>
          <li>
            Often times, when solving problems in computer science, there are a multitude of methods that will get your from the given point A, to the desired point B. Despite this, it is often key to determine which of these potential solutions is the fastest or most efficient when preforming the given tasks. In order to analyze program efficiency, time complexity is used. The "Time complexity of an algorithm quantifies the amount of time taken by an algorithm to run as a function of the length of the input"[2]. The time an algorithm takes to execute depends on a multitude of variables, including hardware, operating system and cpu, however none of these are taken into consideration when analyzing the time complexity of an algorithm.
          </li>
          <br>
        <li>
          Since the time an algorithm needs to run for depends on the input given, the time complexity of a specific algorithm is generally based on the worst case, that being, when the program itself will need to run for the longest possible time. The graph shown at the right depicts how the amount of operations an algorithm must preform (y-axis), differs based on both input data size (x-axis) and the time complexity of that algorithm (labelled functions). More about this can be read in the 'How' section for time complexity.
        </li>
        <div class="space"></div>
        <br>
        <br>
        </ul>
        <h2>  Who is coined to have "created" algorithms? when exactly was this? </h2>
        <img src= image_4.jpg height= "240px"  />
        <ul>
          <li>
            The term 'algorithm' is certainly an ancient one, but what many of us thing of when the word is said is not reminiscent of the origin. The prominence and uprising of algorithms came a very long time ago, about 1600 B.C for that matter, and rose to prominence with the use of variables in mathematics [3]. As previously stated, the use of the first algorithms dates all the way back to the 16th century Babylonians, which used them for factorization and calculating square roots.
          </li>
          <br>
          <li>
            Regardless of the use, the term 'algorithm' itself is thought to go all the way back to the 9th century mathematician,  Abdullah Muhammad ibn Musa Al-Khwarizmi(picture to the right), who is also thought of as the "father of algebra". The word originally started as "algorism", which Al-Khwarizmi used to refer to his use of aribic numerals in arithmetic. Nearing the 18th century, the word evolved into "Allegorism", and finally became the modern, "Algorithm", as we know it to be today. This word now generally refers to, "[...] all definite procedures for solving problems or performing tasks" [3].
          </li>
          <div class="space"></div>
          <br>
          <br>
        </ul>
        <h2>  Who is the "founder" of algorithmic time complexity? When was this breakthrough made? </h2>
        <img src= image_5.jfif height= "150px" />
        <ul>
          <li>
            The idea of creating efficient algorithms is one that can be traced back all the way to the ancient Greeks, however it wasn't until several thousand years later that we began to delve into time and space complexity of various computers and algorithms. The story begins in 1965, with two very prominent figures in the field of computer science, Juris Hartmanis and Richard E. Stearns. Their paper, "On the Computational Complexity of Algorithms" [5], began by analyzing the the time an space complexities of different varities of Turing Machines, which layed the groundwork for where the field stands today.
          </li>
          <br>
          <li>
            Their theories of computational complexity, as previously stated, began with the analysis of turing machines. they quickly determined that the two tape turing machines were able to solve problems much faster than single tape turing machines. This idea was one that kickstarted research into this field of effeicency, and for that, they are considered to be the founders of computational complexity.
          </li>
          <div class="space"></div>
        </ul>
        <h2> Where are algorithms and time complexity used most? </h2>
        <img src= Image_9.png height= "300px" />
        <ul>
          <li>
            The idea of an algorithm is often one that can become convoluted by the complex problems and information that is often seen in solving problems computationally. Algorithms don't just apply to computer science, in fact, they are present in every aspect of our lives, weather that be how we follow a recipe, or adhere to a shopping list. Much like in real life, algorithms are used in computer science to simply accomplish a task, no matter how big or small the task is.  Simply put, algorithms are seen everywhere in the study of computer science. They help us solve problems in a known and efficient manner, and allow us to complete the task at hand effectively. Today, there are a variety of different types of algorithms, including:
          </li>
          <br>
          <div class="para2">
            1.) Recursive - The recursive algorithm is one that calls itself repeatedly until the algorithm is solved. The recursive algorithm, "calls itself with a smaller value as inputs which it gets after solving for the current inputs" [8].
          </div>
          <br>
          <div class="para2">
            2.) Divide and conquer - The divide an conquer algorithm is divided into 2 parts in a sense, one of which divides the problem into smaller subproblems of the same type, and the second part solves these smaller problems, and adds them together to come to a final solution. [8]
          </div>
          <br>
          <div class="para2">
            3.) Dynamic - Dynamic programming algorithms use information stored from previous results and use them to find the solution to the problem at hand. "dynamic programming algorithm solves complex problems by breaking it into multiple simple subproblems and then it solves each of them once and then stores them for future use" [8].
          </div>
          <br>
          <div class="para2">
            4.) Greedy - These types of algorithms are used mainly in optimization problems. Within each stage of solving the problem, it makes the optimal choice, hoping that results in the globally optimal outcome. [8]
          </div>
          <br>
          <div class="para2">
            5.) Brute force - This is arguably the simplest, and most ineffeicent algorithm. The brute force algorithm is one that simply tries all possible solutions to a problem, in hopes of choosing the correct one. [8]
          </div>
          <br>
          <div class="para2">
            6.) Backtracking - Backtracking algorithms can almost be thought of as a mixture between divide and conquer and recursion. These algorithms solve problems recursively, and try to get to the final solution, by solving small portions of the problem at a time. If one of these smaller sub-problem solutions fail, then it undoes the last step, and begins again. [8]
          </div>
          <br>
          <li>
            Completing tasks efficiently is one extremely important part of computation, and is where time complexity comes into play. evaluating the time (and even space) complexity of an algorithm is key to determining the best possible solution to a problem. In simple terms, "time complexity is a way of abstractly describing the run time of any given algorithm. "[6]. It allows us to determine if 'one algorithm is better than another', and promotes more efficient problem solving.
          </li>
          <div class="space"></div>
        </ul>
        <h2> How are algorithms created? </h2>
        <img src= Image_7.png height= "170px" />
        <ul>
          <li>
            Unlike many other things, an algorithm isn't something that is just created at random. Many of today's most prominent algorithms were created because someone needed to solve a problem in a way that a computer would be able to understand. From this problem, a step by step set of instructions were created for the computer to follow, allowing it to carry out the task, and reach the desired outcome. This example does outline the hypothetical series of events that constitute algorithm design and implementation, but in many cases, this simply doesn't happen. Often times, the problems presented are simple for us humans to solve, but making the solution feasible for a computer to preform is where the real struggle comes into play.
          </li>
          <br>
          <li>
            Say, for example, you are tasked with the problem of sorting numbers from least to greatest. For us, that is a menial task, since we can easily identify the "value" that a number possesses, that being its position on a number line, and arrange the numbers accordingly. For a computer, however, this task is quite challenging. Problems like these are what stump the greatest minds of our time to not only create a methodical problem solving method that can be understood by a computer, but optimize it and become the most efficient solution plausible. Despite the ambiguity that surrounds the concrete steps in creating an algorithm, all algorithms should abide by the IPO model. This refers to the three major stages of any algorithm, which include, 'data input', 'data processing', and 'results output'. These three steps mark the major building blocks that any functional algorithm should be based upon.
          </li>
          <div class="space"></div>
        </ul>

        <h2> How is time complexity evaluated? </h2>
        <ul>
          <li>
            when designing an algorithm, or even just choosing the best one for your solution, the time complexity is something that is vitally important. The most prominent type of time complexity is known as the 'worst-case time complexity', and it represents a, "scenario that [the] program may encounter that would require the most time to complete if at all" [7].  The way in which the time complexity of an algorithm is expressed is through what is known as 'Big-O notation'. Big-O notation is the most prominent metric for calculating time complexity, and it describes the, "execution time of a task in relation to the number of steps required to complete it." [7]. This notation is written in the form of 'O(n)', where O stands for 'order of magnitude' and 'n' represents what the complexity is being compared against. Some of the most prominent types of time complexity include:
          </li>
          <br>
          <div class="para2">
            1.) Constant complexity - O(1): the run time of a task with constant time complexity will not change, regardless of the input. Examples iunclude basic operations, such as arithmetic, comparisons and variable assignment. As can be seen from the example in code, the run time of simply outputting a statement will be constant regardless of N. [9]
          </div>
          <br>
          <img src= constantComplexity.PNG width="700"/>
          <div class="space"></div>

          <div class="para2">
            2.) Linear complexity - O(N): unlike constant complexity, the time of a linear task will vary depending on the input value - "it’s run time increases at an order of magnitude proportional to n." [7]. In short, when the computer recieves 'n' inputs, it will preform 'n' operations. The code example represents a program with linear time complexity. The running time is directly related to N. when N triples, so does the time it takes to run, and so on. [9]
          </div>
          <br>
          <img src= linearComplexity.PNG width="700"/>
          <div class="space"></div>
          <br>
          <br>
          <br>

          <div class="para2">
            3.) Quadratic complexity - O(N²): as can probably be assumed, the quadratic task requires a number of steps equal to the square of its input size. Quadratic complexity is generally recognized by a nested loop. The example code below represents quadratic complexity. The time the program takes to run is dependant on 2 loops, and will therefore increase by N*N, or N². [9]
          </div>
          <img src= quadraticComplexity.PNG width="700"/>
          <div class="space"></div>
          <br>
          <br>
          <br>
          <br>
          <br>
          <div class="para2">
            4.) Logarithmic complexity - O(logN): This is the ideal time complexity, as it makes each subsequent step as performed by the computer, faster. Each step preformed by the computer is, "decreased at magnitude inversely proportional to N." [7]. An algorithm with logarithmic time complexity generally divides the problem into smaller sub-problems, of the same size. Examples include binary search and conversion algorithms. The following algorithm will have a logarithmic time complexity because the running time is proportional to the number of times N (high - low) can be divided by 2. [9]
          </div>
          <br>
          <img src= logarithmicComplexity.PNG width="700"/>
          <div class="space"></div>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
          <br>
        </ul>

        <h2> Why are algorithms and time complexity important to understand? </h2>
        <img src= Image_10.jpg height = "300" />
        <ul>
          <li>
            The simple answer regarding the importance of knowing various types of algorithms comes from having the knowledge of when and where to use them. When working on a project, it is key that you have an in depth understanding of a variety of different algorithms and how they work, so that they can be applied appropriately, and their run time can be predicted. As previously mentioned, time complexity and the use of algorithms are two subtopics within computer science that go hand in hand with one another. One cannot be applied effectively without a solid background in the other. [10]
          </li>
          <br>
          <li>
            Of course, the ideal scenario in which an already created and optimized algorithm can be put into place is one that doesn't arise very often. As a result, we will need to think of a way to either create a new algorithm, or apply an already existing algorithm in a new way. In scenarios like these, an in depth knowledge of how algorithms work, and how they can be derived is key to successfully solving the problem at hand.  The more you know about algorithms, the better chance you have at solving the problem in an effective manner, "In many cases, a new problem can be reduced to an old problem without too much effort, but you will need to have a fundamental understanding of the old problem in order to do this. " [10].

          </li>
          <br>
          <li>
            On the other hand, time complexity is something that is extremely important to understand because it not only promotes efficient problem solving, but it allows us to analyze our current solution to a given problem, and make changes in order to decrease run time.  Often times when developing software on a small scale, an efficiency of O(n²) might preform perfectly fine, but will begin to suffer from major hiccups when the tasks that it needs to preform increase in magnitude. For this reason, it is important to apply knowledge of time complexity in order to write code that it able to withstand the pressure of increasing data loads. [4]
          </li>
          <div class="space"></div>
        </ul>

        <h1> Works Cited </h1>
        <ul>
          <li>
            [1] Meinecke, Lonny. (N.D.). "What is an Algorithm in Programming? - Definition, Examples & Analysis" . N/A. Retrieved from
          </li>
          <div class="para2">
            https://study.com/academy/lesson/what-is-an-algorithm-in-programming-definition-examples-analysis.html
          </div>

          <br>

          <li>
            [2] Sharma, Akash. (N.D.). "Time and Space Complexity.". N/A. Retrieved from
          </li>
          <div class="para2">
            hackerearth.com/practice/basic-programming/complexity-analysis/time-and-space-complexity/tutorial/
          </div>

          <br>

          <li>
            [3] McFadden, Christopher. (January 30, 2017). "The Origin Of Algorithms We Use Every Single Day". N/A. Retrieved from
          </li>
          <div class="para2">
            https://interestingengineering.com/origin-algorithms-use-every-day
          </div>

          <br>

          <li>
            [4] McCreary, Doug. (Sept 24, 2016). "Why is it necessary to know the time complexity of an algorithm?". N/A. Retrieved from
          </li>
          <div class="para2">
            https://www.quora.com/Why-is-it-necessary-to-know-the-time-complexity-of-a-program
          </div>

          <br>

          <li>
            [5] Fortnow, Lance. (N.D.). "A Short Complexity of Computational Complexity". Princeton, New Jersey. Retrieved from
          </li>
          <div class="para2">
            people.cs.uchicago.edu/~fortnow/beatcs/column80.pdf
          </div>

          <br>

          <li>
            [6] Bongiorno, Christian. (Dec 9, 2014). "What are algorithms actually used for". N/A. Retrieved from
          </li>
          <div class="para2">
            https://www.quora.com/What-are-algorithms-actually-used-for
          </div>

          <br>

          <li>
            [7] Kuredjian, Stuart. (Mar 11, 2017). "Algorithm time complexity and big O notation". N/A. Retrieved from
          </li>
          <div class="para2">
            https://medium.com/@StueyGK/algorithm-time-complexity-and-big-o-notation-51502e612b4d
          </div>

          <br>

          <li>
            [8] EDUCBA. (N.D). "Types of Algorithms". N/A. Retrieved from
          </li>
          <div class="para2">
            https://www.educba.com/types-of-algorithms/
          </div>

          <br>

          <li>
            [9] Ahlawat, Abhishek. (N.D). "Time Complexity of Algorithms". N/A. Retrieved from
          </li>
          <div class="para2">
            https://www.studytonight.com/data-structures/time-complexity-of-algorithms
          </div>

          <br>

          <li>
            [10] Masood, Abdur. (Jun 12, 2017). "Understanding Time Complexities and its importance in Technology". N/A. Retrieved from
          </li>
          <div class="para2">
            https://medium.com/@abdurrafeymasood/understanding-time-complexity-and-its-importance-in-technology-8279f72d1c6a
          </div>

          <div class="space"></div>
        <ul>

    </body>
</html>
